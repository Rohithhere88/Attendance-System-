{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rohithhere88/Attendance-System-/blob/main/MiniProject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7z33KFTeyTEp"
      },
      "source": [
        "!pip install -q dlib face_recognition\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oe7KNR1p38Bq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CjqeF33lVBi_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "print(\"GPU Available:\", torch.cuda.is_available())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "i50w5Zi87zhi",
        "outputId": "2342740e-8cc1-4b24-d581-0f2e1688d869"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (25.1.24)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.25.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.70.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow) (0.14.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Collecting face_recognition\n",
            "  Downloading face_recognition-1.3.0-py2.py3-none-any.whl.metadata (21 kB)\n",
            "Collecting face-recognition-models>=0.3.0 (from face_recognition)\n",
            "  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.1/100.1 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.11/dist-packages (from face_recognition) (8.1.8)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.11/dist-packages (from face_recognition) (19.24.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from face_recognition) (1.26.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from face_recognition) (11.1.0)\n",
            "Downloading face_recognition-1.3.0-py2.py3-none-any.whl (15 kB)\n",
            "Building wheels for collected packages: face-recognition-models\n",
            "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566162 sha256=376ae35764cd2cb525d2396ecc6e81d6f1bb0270842b1fce8c802e377d2f7f3c\n",
            "  Stored in directory: /root/.cache/pip/wheels/04/52/ec/9355da79c29f160b038a20c784db2803c2f9fa2c8a462c176a\n",
            "Successfully built face-recognition-models\n",
            "Installing collected packages: face-recognition-models, face_recognition\n",
            "Successfully installed face-recognition-models-0.3.0 face_recognition-1.3.0\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Model loaded from disk\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    var video;\n",
              "    var div = null;\n",
              "    var stream;\n",
              "    var captureCanvas;\n",
              "    var imgElement;\n",
              "    var labelElement;\n",
              "\n",
              "    var pendingResolve = null;\n",
              "    var shutdown = false;\n",
              "\n",
              "    function removeDom() {\n",
              "       stream.getVideoTracks()[0].stop();\n",
              "       video.remove();\n",
              "       div.remove();\n",
              "       video = null;\n",
              "       div = null;\n",
              "       stream = null;\n",
              "       imgElement = null;\n",
              "       captureCanvas = null;\n",
              "       labelElement = null;\n",
              "    }\n",
              "\n",
              "    function onAnimationFrame() {\n",
              "      if (!shutdown) {\n",
              "        window.requestAnimationFrame(onAnimationFrame);\n",
              "      }\n",
              "      if (pendingResolve) {\n",
              "        var result = \"\";\n",
              "        if (!shutdown) {\n",
              "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
              "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
              "        }\n",
              "        var lp = pendingResolve;\n",
              "        pendingResolve = null;\n",
              "        lp(result);\n",
              "      }\n",
              "    }\n",
              "\n",
              "    async function createDom() {\n",
              "      if (div !== null) {\n",
              "        return stream;\n",
              "      }\n",
              "\n",
              "      div = document.createElement('div');\n",
              "      div.style.border = '2px solid black';\n",
              "      div.style.padding = '3px';\n",
              "      div.style.width = '100%';\n",
              "      div.style.maxWidth = '600px';\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const modelOut = document.createElement('div');\n",
              "      modelOut.innerHTML = \"Status:\";\n",
              "      labelElement = document.createElement('span');\n",
              "      labelElement.innerText = 'No data';\n",
              "      labelElement.style.fontWeight = 'bold';\n",
              "      modelOut.appendChild(labelElement);\n",
              "      div.appendChild(modelOut);\n",
              "\n",
              "      video = document.createElement('video');\n",
              "      video.style.display = 'block';\n",
              "      video.width = div.clientWidth - 6;\n",
              "      video.setAttribute('playsinline', '');\n",
              "      video.onclick = () => { shutdown = true; };\n",
              "      stream = await navigator.mediaDevices.getUserMedia(\n",
              "          {video: { facingMode: \"environment\"}});\n",
              "      div.appendChild(video);\n",
              "\n",
              "      imgElement = document.createElement('img');\n",
              "      imgElement.style.position = 'absolute';\n",
              "      imgElement.style.zIndex = 1;\n",
              "      imgElement.onclick = () => { shutdown = true; };\n",
              "      div.appendChild(imgElement);\n",
              "\n",
              "      const instruction = document.createElement('div');\n",
              "      instruction.innerHTML =\n",
              "          '' +\n",
              "          'When finished, click here or on the video to stop this demo';\n",
              "      div.appendChild(instruction);\n",
              "      instruction.onclick = () => { shutdown = true; };\n",
              "\n",
              "      video.srcObject = stream;\n",
              "      await video.play();\n",
              "\n",
              "      captureCanvas = document.createElement('canvas');\n",
              "      captureCanvas.width = 640; //video.videoWidth;\n",
              "      captureCanvas.height = 480; //video.videoHeight;\n",
              "      window.requestAnimationFrame(onAnimationFrame);\n",
              "\n",
              "      return stream;\n",
              "    }\n",
              "    async function stream_frame(label, imgData) {\n",
              "      if (shutdown) {\n",
              "        removeDom();\n",
              "        shutdown = false;\n",
              "        return '';\n",
              "      }\n",
              "\n",
              "      var preCreate = Date.now();\n",
              "      stream = await createDom();\n",
              "\n",
              "      var preShow = Date.now();\n",
              "      if (label != \"\") {\n",
              "        labelElement.innerHTML = label;\n",
              "      }\n",
              "\n",
              "      if (imgData != \"\") {\n",
              "        var videoRect = video.getClientRects()[0];\n",
              "        imgElement.style.top = videoRect.top + \"px\";\n",
              "        imgElement.style.left = videoRect.left + \"px\";\n",
              "        imgElement.style.width = videoRect.width + \"px\";\n",
              "        imgElement.style.height = videoRect.height + \"px\";\n",
              "        imgElement.src = imgData;\n",
              "      }\n",
              "\n",
              "      var preCapture = Date.now();\n",
              "      var result = await new Promise(function(resolve, reject) {\n",
              "        pendingResolve = resolve;\n",
              "      });\n",
              "      shutdown = false;\n",
              "\n",
              "      return {'create': preShow - preCreate,\n",
              "              'show': preCapture - preShow,\n",
              "              'capture': Date.now() - preCapture,\n",
              "              'img': result};\n",
              "    }\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "number 0\n",
            "just came/...\n",
            "number 1\n",
            "just came/...\n",
            "number 2\n",
            "just came/...\n",
            "number 3\n",
            "just came/...\n",
            "number 4\n",
            "just came/...\n",
            "number 5\n",
            "just came/...\n",
            "number 6\n",
            "just came/...\n",
            "0 Login time\n",
            "NO match found\n"
          ]
        }
      ],
      "source": [
        "#--------CODE FOR INPUT IMAGE TAKING-----------------\n",
        "print()\n",
        "from IPython.display import display, Javascript, Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode, b64encode\n",
        "import cv2\n",
        "import numpy as np\n",
        "import PIL\n",
        "import io\n",
        "# import html\n",
        "import time\n",
        "import os\n",
        "!pip install tensorflow\n",
        "from tensorflow.keras.models import model_from_json\n",
        "import smtplib\n",
        "import ssl\n",
        "from email.message import EmailMessage\n",
        "from datetime import datetime\n",
        "import collections\n",
        "from pytz import timezone\n",
        "!pip install face_recognition\n",
        "import concurrent.futures\n",
        "import face_recognition\n",
        "import os\n",
        "import shutil\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# Load known faces\n",
        "known_faces_dir = \"/content/drive/MyDrive/Colab Notebooks/Real Time Face Recognition System/face_recognition\"\n",
        "known_face_names = []\n",
        "known_face_encodings = []\n",
        "resulted_founded_names = []\n",
        "d = collections.defaultdict(lambda : 'Not found')\n",
        "d ['RohiTh'] = ['2022it0093@svce.ac.in','2127220801072'] ;       d['Vinoth kanna'] = ['2022it0545@svce.ac.in' ,'Number__solra']\n",
        "d ['Thiwahar']  = ['2022it0535@svce.ac.in','2127220801101'] ;  d['Sanjay Ram']  = ['2022it0899@svce.ac.in', '2127220801076']\n",
        "curr_folder_path = \"/content/drive/MyDrive/Colab Notebooks/Real Time Face Recognition System/spoofing\"\n",
        "\n",
        "root_dir = os.getcwd()\n",
        "# Load Face Detection Model\n",
        "face_cascade = cv2.CascadeClassifier(\"models/haarcascade_frontalface_default.xml\")\n",
        "# Load Anti-Spoofing Model graph\n",
        "json_file = open(\"/content/drive/MyDrive/Colab Notebooks/Real Time Face Recognition System/anti-spoofing.json\",'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "model = model_from_json(loaded_model_json)\n",
        "# load antispoofing model weights\n",
        "\n",
        "print(\"Model loaded from disk\")\n",
        "#\n",
        "#-------CODE for Recognition and attendance marking---\n",
        "for filename in os.listdir(known_faces_dir):\n",
        "    if not filename.startswith('.'):\n",
        "        image = face_recognition.load_image_file(os.path.join(known_faces_dir, filename))\n",
        "        face_encodings = face_recognition.face_encodings(image, num_jitters=10, model=\"large\")\n",
        "        if face_encodings:\n",
        "            known_face_encodings.append(face_encodings[0])\n",
        "            known_face_names.append(os.path.splitext(filename)[0])\n",
        "\n",
        "# function to convert the JavaScript object into an OpenCV image\n",
        "def js_to_image(js_reply):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          js_reply: JavaScript object containing image from webcam\n",
        "  Returns:\n",
        "          img: OpenCV BGR image\n",
        "  \"\"\"\n",
        "  # decode base64 image\n",
        "  image_bytes = b64decode(js_reply.split(',')[1])\n",
        "  # convert bytes to numpy array\n",
        "  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "  # decode numpy array into OpenCV BGR image\n",
        "  img = cv2.imdecode(jpg_as_np, flags=1)\n",
        "\n",
        "  return img\n",
        "\n",
        "# function to convert OpenCV Rectangle bounding box image into base64 byte string to be overlayed on video stream\n",
        "def bbox_to_bytes(bbox_array):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          bbox_array: Numpy array (pixels) containing rectangle to overlay on video stream.\n",
        "  Returns:\n",
        "        bytes: Base64 image byte string\n",
        "  \"\"\"\n",
        "  # convert array into PIL image\n",
        "  bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\n",
        "  iobuf = io.BytesIO()\n",
        "  # format bbox into png for return\n",
        "  bbox_PIL.save(iobuf, format='png')\n",
        "  # format return string\n",
        "  bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\n",
        "\n",
        "  return bbox_bytes\n",
        "\n",
        "# initialize the Haar Cascade face detection model\n",
        "face_cascade = cv2.CascadeClassifier(cv2.samples.findFile(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'))\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "\n",
        "  # get photo data\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  # get OpenCV format image\n",
        "  img = js_to_image(data)\n",
        "  # grayscale img\n",
        "  gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "  print(gray.shape)\n",
        "  # get face bounding box coordinates using Haar Cascade\n",
        "  faces = face_cascade.detectMultiScale(gray)\n",
        "  # draw face bounding box on image\n",
        "  for (x,y,w,h) in faces:\n",
        "      img = cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
        "  # save image\n",
        "  cv2.imwrite(filename, img)\n",
        "\n",
        "  return filename\n",
        "\n",
        "# JavaScript to properly create our live video stream using our webcam as input\n",
        "def video_stream():\n",
        "  js = Javascript('''\n",
        "    var video;\n",
        "    var div = null;\n",
        "    var stream;\n",
        "    var captureCanvas;\n",
        "    var imgElement;\n",
        "    var labelElement;\n",
        "\n",
        "    var pendingResolve = null;\n",
        "    var shutdown = false;\n",
        "\n",
        "    function removeDom() {\n",
        "       stream.getVideoTracks()[0].stop();\n",
        "       video.remove();\n",
        "       div.remove();\n",
        "       video = null;\n",
        "       div = null;\n",
        "       stream = null;\n",
        "       imgElement = null;\n",
        "       captureCanvas = null;\n",
        "       labelElement = null;\n",
        "    }\n",
        "\n",
        "    function onAnimationFrame() {\n",
        "      if (!shutdown) {\n",
        "        window.requestAnimationFrame(onAnimationFrame);\n",
        "      }\n",
        "      if (pendingResolve) {\n",
        "        var result = \"\";\n",
        "        if (!shutdown) {\n",
        "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
        "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
        "        }\n",
        "        var lp = pendingResolve;\n",
        "        pendingResolve = null;\n",
        "        lp(result);\n",
        "      }\n",
        "    }\n",
        "\n",
        "    async function createDom() {\n",
        "      if (div !== null) {\n",
        "        return stream;\n",
        "      }\n",
        "\n",
        "      div = document.createElement('div');\n",
        "      div.style.border = '2px solid black';\n",
        "      div.style.padding = '3px';\n",
        "      div.style.width = '100%';\n",
        "      div.style.maxWidth = '600px';\n",
        "      document.body.appendChild(div);\n",
        "\n",
        "      const modelOut = document.createElement('div');\n",
        "      modelOut.innerHTML = \"Status:\";\n",
        "      labelElement = document.createElement('span');\n",
        "      labelElement.innerText = 'No data';\n",
        "      labelElement.style.fontWeight = 'bold';\n",
        "      modelOut.appendChild(labelElement);\n",
        "      div.appendChild(modelOut);\n",
        "\n",
        "      video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      video.width = div.clientWidth - 6;\n",
        "      video.setAttribute('playsinline', '');\n",
        "      video.onclick = () => { shutdown = true; };\n",
        "      stream = await navigator.mediaDevices.getUserMedia(\n",
        "          {video: { facingMode: \"environment\"}});\n",
        "      div.appendChild(video);\n",
        "\n",
        "      imgElement = document.createElement('img');\n",
        "      imgElement.style.position = 'absolute';\n",
        "      imgElement.style.zIndex = 1;\n",
        "      imgElement.onclick = () => { shutdown = true; };\n",
        "      div.appendChild(imgElement);\n",
        "\n",
        "      const instruction = document.createElement('div');\n",
        "      instruction.innerHTML =\n",
        "          '' +\n",
        "          'When finished, click here or on the video to stop this demo';\n",
        "      div.appendChild(instruction);\n",
        "      instruction.onclick = () => { shutdown = true; };\n",
        "\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      captureCanvas = document.createElement('canvas');\n",
        "      captureCanvas.width = 640; //video.videoWidth;\n",
        "      captureCanvas.height = 480; //video.videoHeight;\n",
        "      window.requestAnimationFrame(onAnimationFrame);\n",
        "\n",
        "      return stream;\n",
        "    }\n",
        "    async function stream_frame(label, imgData) {\n",
        "      if (shutdown) {\n",
        "        removeDom();\n",
        "        shutdown = false;\n",
        "        return '';\n",
        "      }\n",
        "\n",
        "      var preCreate = Date.now();\n",
        "      stream = await createDom();\n",
        "\n",
        "      var preShow = Date.now();\n",
        "      if (label != \"\") {\n",
        "        labelElement.innerHTML = label;\n",
        "      }\n",
        "\n",
        "      if (imgData != \"\") {\n",
        "        var videoRect = video.getClientRects()[0];\n",
        "        imgElement.style.top = videoRect.top + \"px\";\n",
        "        imgElement.style.left = videoRect.left + \"px\";\n",
        "        imgElement.style.width = videoRect.width + \"px\";\n",
        "        imgElement.style.height = videoRect.height + \"px\";\n",
        "        imgElement.src = imgData;\n",
        "      }\n",
        "\n",
        "      var preCapture = Date.now();\n",
        "      var result = await new Promise(function(resolve, reject) {\n",
        "        pendingResolve = resolve;\n",
        "      });\n",
        "      shutdown = false;\n",
        "\n",
        "      return {'create': preShow - preCreate,\n",
        "              'show': preCapture - preShow,\n",
        "              'capture': Date.now() - preCapture,\n",
        "              'img': result};\n",
        "    }\n",
        "    ''')\n",
        "\n",
        "  display(js)\n",
        "\n",
        "def video_frame(label, bbox):\n",
        "  data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\n",
        "  return data\n",
        "\n",
        "\n",
        "# start streaming video from webcam\n",
        "video_stream()\n",
        "# label for video\n",
        "label_html = 'Capturing...'\n",
        "# initialze bounding box to empty\n",
        "bbox = ''\n",
        "count = 0\n",
        "i =0\n",
        "reali = 0 ; name = \"\" ; label = \"Proxy\" ; resulted_founded_names = []\n",
        "while True:\n",
        "    js_reply = video_frame(label_html, bbox)\n",
        "    if not js_reply:\n",
        "        i = 0 ; reali = 0\n",
        "        break\n",
        "\n",
        "    # convert JS response to OpenCV Image\n",
        "    img = js_to_image(js_reply[\"img\"])\n",
        "\n",
        "    # create transparent overlay for bounding box\n",
        "    bbox_array = np.zeros([480,640,4], dtype=np.uint8)\n",
        "\n",
        "    #\n",
        "    frame = img\n",
        "    #\n",
        "\n",
        "    # grayscale image for face detection\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "    try:\n",
        "      faces = face_cascade.detectMultiScale(gray,1.3,5)\n",
        "      for (x,y,w,h) in faces:\n",
        "        print(\"number\",i); i+=1\n",
        "        face = frame[y-5:y+h+5,x-5:x+w+5]\n",
        "        resized_face = cv2.resize(face,(160,160))\n",
        "        resized_face = resized_face.astype(\"float\") / 255.0\n",
        "        # resized_face = img_to_array(resized_face)\n",
        "        resized_face = np.expand_dims(resized_face, axis=0)\n",
        "        # pass the face ROI through the trained liveness detector\n",
        "        # model to determine if the face is \"real\" or \"Proxy\"\n",
        "        print(\"just came/...\")\n",
        "        preds = model.predict(resized_face)[0]\n",
        "        print(\">>preds>>\",preds)\n",
        "        if preds> 0.5:\n",
        "            label = 'spoof'\n",
        "            cv2.putText(frame, label, (x,y - 10),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,255), 2)\n",
        "            cv2.rectangle(frame, (x, y), (x+w,y+h),\n",
        "                (0, 0, 255), 2)\n",
        "        else:\n",
        "            label = 'real'\n",
        "            reali += 1\n",
        "            cv2.putText(frame, label, (x,y - 10),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 2)\n",
        "            cv2.rectangle(frame, (x, y), (x+w,y+h),\n",
        "            (0, 255, 0), 2)\n",
        "        # save image\n",
        "        filename = \"photo.jpg\"\n",
        "        cv2.imwrite(filename, frame)\n",
        "        print('Saved to {}'.format(filename))\n",
        "        display(Image(filename))\n",
        "        print(\"result>>\",label)\n",
        "    except: pass\n",
        "#----------------------------------------------------\n",
        "    if label =='real':\n",
        "      label = \"Proxy\"\n",
        "      # Load test image\n",
        "      test_image_path = \"/content/photo.jpg\"\n",
        "      test_image = face_recognition.load_image_file(test_image_path)\n",
        "\n",
        "      # Define face recognition function\n",
        "      def recognize_face(face_encoding):\n",
        "          matches = face_recognition.compare_faces(known_face_encodings, face_encoding, tolerance=0.4)\n",
        "          if True in matches:\n",
        "              match_index = matches.index(True)\n",
        "              name = known_face_names[match_index]\n",
        "              return name\n",
        "          else:\n",
        "              return None\n",
        "\n",
        "      # Find faces in test image\n",
        "      face_locations = face_recognition.face_locations(test_image, model='cnn')\n",
        "      face_encodings = face_recognition.face_encodings(test_image, face_locations, num_jitters=10, model=\"large\")\n",
        "\n",
        "      # Create or open attendance file in append mode\n",
        "      attendance_file = open(\"/content/drive/MyDrive/Colab Notebooks/Real Time Face Recognition System/Attendance folder/Attendance.txt\", \"a\")\n",
        "\n",
        "\n",
        "      # Check if test image contains at least one face\n",
        "      if not face_encodings:\n",
        "          print(\"No faces found in test image.\")\n",
        "      else:\n",
        "          # Parallelize face recognition process\n",
        "          with concurrent.futures.ProcessPoolExecutor() as executor:\n",
        "              results = executor.map(recognize_face, face_encodings)\n",
        "          resulted_founded_names = list(results)\n",
        "          # Write attendance to file\n",
        "          for i, result in enumerate(results):\n",
        "              if result:\n",
        "                  name = result\n",
        "                  resulted_founded_names.append(name)\n",
        "                  print(f\"Match found: {name}\")\n",
        "\n",
        "              else:\n",
        "                  print(\"No match found.\")\n",
        "      #-----------------------------------------------------\n",
        "\n",
        "    #--------CODE FOR EMAIL SENDING ----------------------\n",
        "import smtplib\n",
        "import ssl\n",
        "from email.message import EmailMessage\n",
        "from datetime import datetime\n",
        "import collections\n",
        "from pytz import timezone\n",
        "resulted_founded_names = ['RohiTh']\n",
        "d = collections.defaultdict(lambda : 'Not found')\n",
        "d ['RohiTh'] = ['2022it0093@svce.ac.in','2127220801072'] ;       d['Praveen'] = ['2022it0109@svce.ac.in' ,'Number__solra']\n",
        "d ['Thiwahar']  = ['2022it0535@svce.ac.in','2127220801101'] ;  d['Sanjay Ram']  = ['2022it0899@svce.ac.in', '2127220801076']\n",
        "for name in resulted_founded_names:\n",
        "  try:\n",
        "    if d[name] == 'Not found': pass\n",
        "\n",
        "  ##################################\n",
        "    def update_login(student_name):\n",
        "      file_path = '/content/drive/MyDrive/AutoMailingFeatureForAttendanceSystem/login.txt'\n",
        "      # student_name = input(\"Enter student name: \")\n",
        "\n",
        "      with open(file_path, 'r') as file:\n",
        "          lines = file.readlines()\n",
        "      # print(\"initial>\",lines)\n",
        "\n",
        "      found = 0\n",
        "      new_lines = []\n",
        "\n",
        "      for line in lines:\n",
        "          if line.strip() == student_name:\n",
        "              found = 1\n",
        "              print(found,\"<<\")\n",
        "              continue\n",
        "          else:\n",
        "              new_lines.append(line)\n",
        "\n",
        "      if not found:\n",
        "          new_lines.append(student_name + '\\n')\n",
        "\n",
        "      with open(file_path, 'w') as file:\n",
        "          file.writelines(new_lines)\n",
        "\n",
        "      with open(file_path, 'r') as file:\n",
        "          lines = file.readlines()\n",
        "      return found\n",
        "      # print(\"final>\",lines)\n",
        "    ##################################\n",
        "    founded = update_login(name)\n",
        "    res_loginRout = \"Login time\"\n",
        "    if founded: res_loginRout = \"Logout time\"\n",
        "    print(founded,res_loginRout)\n",
        "    for i in range(1):\n",
        "      # Get the current date and time\n",
        "      now = datetime.now(timezone(\"Asia/Kolkata\"))\n",
        "      current_time = now.strftime(\"%H:%M:%S\")\n",
        "      current_date = now.strftime(\"%d/%m/%Y\")\n",
        "\n",
        "      # for i in range(10):\n",
        "      # Define email sender and receiver\n",
        "      email_sender = 'rohith777here@gmail.com'\n",
        "      email_password = 'ckek bcij lhkh fqmi'\n",
        "      email_receiver = d[name][0]#'skgouse131@gmail'#'bnagaseshu2001@gmail.com'#'vilasagaram.vikas@gmail.com'#'skgouse131@gmail.com'\n",
        "\n",
        "      # Set the subject and body of the email\n",
        "      subject = 'SVCE REAL-TIME FACE RECOGNITION BASED ATTENDANCE MONITORING SYSTEM.'#'Check out Your ward attendance!'\n",
        "      body = f\"\"\"\n",
        "      <<<<<<<<<<<<<   YOUR ATTENDANCE   >>>>>>>>>>>>>>>\n",
        "      -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "      RollNo : {d[name][1]}\n",
        "      NAME : {name}\n",
        "      DATE : {current_date}\n",
        "      TIME : {current_time}\n",
        "      {name} {res_loginRout} attended on {current_date} at {current_time} has successfully marked the attendance.\n",
        "      ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "      Dear {d[name][0]}, \\n\n",
        "      This message is from Organisation/college automatic attendance system. \\n\n",
        "      Your attendance has been successfully marked using the face recognition system. This means that you have been present and accounted for during work hours. I would like to take this opportunity to congratulate you on your successful use of the system.\n",
        "      \\n\n",
        "      The face recognition system has also enhanced our security measures, as it only allows authorized personnel with registered faces to enter the premises. This ensures that our workplace remains safe and secure at all times.\n",
        "      \\n\n",
        "      As a Organisation/college attendance system would like to remind you to continue using the face recognition system for attendance marking. It is important that we maintain accurate attendance records to ensure that everyone is accounted for during work hours..\n",
        "      \\n\n",
        "      Thank you for your attention to this matter.\n",
        "      \\n\n",
        "      Best regards,\n",
        "      \\n\n",
        "      {name}\"\"\"\n",
        "\n",
        "      em = EmailMessage()\n",
        "      em['From'] = 'XYZ'#email_sender\n",
        "      em['To'] = email_receiver\n",
        "      em['Subject'] = subject\n",
        "      em.set_content(body)\n",
        "\n",
        "      # Add SSL (layer of security)\n",
        "      context = ssl.create_default_context()\n",
        "\n",
        "      # Log in and send the email\n",
        "      with smtplib.SMTP_SSL('smtp.gmail.com', 465, context=context) as smtp:\n",
        "          smtp.login(email_sender, email_password)\n",
        "          smtp.sendmail(email_sender, email_receiver, em.as_string())\n",
        "      print(f\"emailsent to {name}\")\n",
        "    resulted_founded_names = []\n",
        "  except:\n",
        "    print(\"NO match found\")\n",
        "#------------------------------------------------------------------------\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "uaD4uXI8ODII"
      },
      "outputs": [],
      "source": [
        "print()\n",
        "from IPython.display import display, Javascript, Image\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode, b64encode\n",
        "import cv2\n",
        "import numpy as np\n",
        "import PIL\n",
        "import io\n",
        "import html\n",
        "import time\n",
        "import os\n",
        "!pip install tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FvCyiPEjOTn3"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import model_from_json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "GSnTT3i3Ofmp"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow --upgrade\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3rLwfw8GOlOz"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)  # Should print 2.x.x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-LyOOqCaPNFE"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import model_from_json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9v70CI81Pgg3",
        "outputId": "f36f71d1-9a91-4eff-c2b2-6430874c63fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: face_recognition in /usr/local/lib/python3.11/dist-packages (1.3.0)\n",
            "Requirement already satisfied: face-recognition-models>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from face_recognition) (0.3.0)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.11/dist-packages (from face_recognition) (8.1.8)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.11/dist-packages (from face_recognition) (19.24.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from face_recognition) (1.26.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from face_recognition) (11.1.0)\n"
          ]
        }
      ],
      "source": [
        "import smtplib\n",
        "import ssl\n",
        "from email.message import EmailMessage\n",
        "from datetime import datetime\n",
        "import collections\n",
        "from pytz import timezone\n",
        "!pip install face_recognition\n",
        "import concurrent.futures\n",
        "import face_recognition\n",
        "import os\n",
        "import shutil\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Force the code to run on CPU\n",
        "import os\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'  # Set to -1 to disable GPU\n",
        "\n",
        "# Load known faces\n",
        "known_faces_dir = \"/content/drive/MyDrive/Colab Notebooks/Real Time Face Recognition System/face_recognition\"\n",
        "known_face_names = []\n",
        "known_face_encodings = []\n",
        "resulted_founded_names = []\n",
        "d = collections.defaultdict(lambda : 'Not found')\n",
        "d ['RohiTh'] = ['2022it0093@svce.ac.in','2127220801072'] ;       d['Vinoth kanna'] = ['2022it0545@svce.ac.in' ,'Number__solra']\n",
        "d ['Thiwahar']  = ['2022it0535@svce.ac.in','2127220801101'] ;  d['Sanjay Ram']  = ['2022it0899@svce.ac.in', '2127220801076']\n",
        "curr_folder_path = \"/content/drive/MyDrive/Colab Notebooks/Real Time Face Recognition System/spoofing\"\n",
        "\n",
        "root_dir = os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Isk0x5waT3dY"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Import necessary modules for Functional API\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import model_from_json\n",
        "from tensorflow.keras.layers import Input, Dense, Conv2D, BatchNormalization, Activation, MaxPooling2D, AveragePooling2D, GlobalAveragePooling2D, concatenate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KeC8UaAXRW5L"
      },
      "outputs": [],
      "source": [
        "import cv2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LL1tOeeERYMF"
      },
      "outputs": [],
      "source": [
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hC_kbYjNRv4G",
        "outputId": "acbc0d39-7144-4b9f-b055-c45e5f78caeb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File exists! ✅\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "file_path = curr_folder_path= \"/content/drive/MyDrive/Colab Notebooks/Real Time Face Recognition System/spoofing/antispoofing_model (1).json\"\n",
        "\n",
        "# Check if the file exists\n",
        "if os.path.exists(file_path):\n",
        "    print(\"File exists! ✅\")\n",
        "else:\n",
        "    print(\"File NOT found! ❌ Check the file path.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xBLiS-z8SBA1"
      },
      "source": [
        "json_file = open(curr_folder_path+'/antispoofing_model (1).json','r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "model = model_from_json(loaded_model_json)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rfPADD4mdXi8"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import model_from_json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "UpcsnLjJW2EF"
      },
      "outputs": [],
      "source": [
        "json_file = open(\"/content/drive/MyDrive/Colab Notebooks/Real Time Face Recognition System/anti-spoofing.json\",'r')\n",
        "loaded_model_json = json_file.read()\n",
        "json_file.close()\n",
        "\n",
        "\n",
        "model = model_from_json(loaded_model_json)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "og0K-5zSaSDa"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "hsJwswOQWpen",
        "outputId": "da1c4a7a-1b1a-4750-bda6-02ebc03132db"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'known_faces_dir' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-1ed96b4e7704>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mknown_faces_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_recognition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_image_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mknown_faces_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;31m# Explicitly use the \"cpu\" model for face detection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mface_encodings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_recognition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mface_encodings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_jitters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"large\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'known_faces_dir' is not defined"
          ]
        }
      ],
      "source": [
        "for filename in os.listdir(known_faces_dir):\n",
        "    if not filename.startswith('.'):\n",
        "        image = face_recognition.load_image_file(os.path.join(known_faces_dir, filename))\n",
        "        # Explicitly use the \"cpu\" model for face detection\n",
        "        face_encodings = face_recognition.face_encodings(image, num_jitters=10, model=\"large\")\n",
        "        if face_encodings:\n",
        "            known_face_encodings.append(face_encodings[0])\n",
        "            known_face_names.append(os.path.splitext(filename)[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZAn7NvBbW0H0"
      },
      "outputs": [],
      "source": [
        "# function to convert the JavaScript object into an OpenCV image\n",
        "def js_to_image(js_reply):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          js_reply: JavaScript object containing image from webcam\n",
        "  Returns:\n",
        "          img: OpenCV BGR image\n",
        "  \"\"\"\n",
        "  # decode base64 image\n",
        "  image_bytes = b64decode(js_reply.split(',')[1])\n",
        "  # convert bytes to numpy array\n",
        "  jpg_as_np = np.frombuffer(image_bytes, dtype=np.uint8)\n",
        "  # decode numpy array into OpenCV BGR image\n",
        "  img = cv2.imdecode(jpg_as_np, flags=1)\n",
        "\n",
        "  return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "TSw91RElJsr3"
      },
      "outputs": [],
      "source": [
        "# function to convert OpenCV Rectangle bounding box image into base64 byte string to be overlayed on video stream\n",
        "def bbox_to_bytes(bbox_array):\n",
        "  \"\"\"\n",
        "  Params:\n",
        "          bbox_array: Numpy array (pixels) containing rectangle to overlay on video stream.\n",
        "  Returns:\n",
        "        bytes: Base64 image byte string\n",
        "  \"\"\"\n",
        "  # convert array into PIL image\n",
        "  bbox_PIL = PIL.Image.fromarray(bbox_array, 'RGBA')\n",
        "  iobuf = io.BytesIO()\n",
        "  # format bbox into png for return\n",
        "  bbox_PIL.save(iobuf, format='png')\n",
        "  # format return string\n",
        "  bbox_bytes = 'data:image/png;base64,{}'.format((str(b64encode(iobuf.getvalue()), 'utf-8')))\n",
        "\n",
        "  return bbox_bytes\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "dcPKMO3rJueG"
      },
      "outputs": [],
      "source": [
        "# initialize the Haar Cascade face detection model\n",
        "face_cascade = cv2.CascadeClassifier(cv2.samples.findFile(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'))\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "  js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "  display(js)\n",
        "  data = eval_js('takePhoto({})'.format(quality))\n",
        "  # get OpenCV format image\n",
        "  img = js_to_image(data)\n",
        "  # grayscale img\n",
        "  gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "  print(gray.shape)\n",
        "  # get face bounding box coordinates using Haar Cascade\n",
        "  faces = face_cascade.detectMultiScale(gray)\n",
        "  # draw face bounding box on image\n",
        "  for (x,y,w,h) in faces:\n",
        "      img = cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)\n",
        "  # save image\n",
        "  cv2.imwrite(filename, img)\n",
        "\n",
        "  return filename\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZfvLespnKbsA"
      },
      "outputs": [],
      "source": [
        "# JavaScript to properly create our live video stream using our webcam as input\n",
        "def video_stream():\n",
        "  js = Javascript('''\n",
        "    var video;\n",
        "    var div = null;\n",
        "    var stream;\n",
        "    var captureCanvas;\n",
        "    var imgElement;\n",
        "    var labelElement;\n",
        "\n",
        "    var pendingResolve = null;\n",
        "    var shutdown = false;\n",
        "\n",
        "    function removeDom() {\n",
        "       stream.getVideoTracks()[0].stop();\n",
        "       video.remove();\n",
        "       div.remove();\n",
        "       video = null;\n",
        "       div = null;\n",
        "       stream = null;\n",
        "       imgElement = null;\n",
        "       captureCanvas = null;\n",
        "       labelElement = null;\n",
        "    }\n",
        "\n",
        "    function onAnimationFrame() {\n",
        "      if (!shutdown) {\n",
        "        window.requestAnimationFrame(onAnimationFrame);\n",
        "      }\n",
        "      if (pendingResolve) {\n",
        "        var result = \"\";\n",
        "        if (!shutdown) {\n",
        "          captureCanvas.getContext('2d').drawImage(video, 0, 0, 640, 480);\n",
        "          result = captureCanvas.toDataURL('image/jpeg', 0.8)\n",
        "        }\n",
        "        var lp = pendingResolve;\n",
        "        pendingResolve = null;\n",
        "        lp(result);\n",
        "      }\n",
        "    }\n",
        "\n",
        "    async function createDom() {\n",
        "      if (div !== null) {\n",
        "        return stream;\n",
        "      }\n",
        "\n",
        "      div = document.createElement('div');\n",
        "      div.style.border = '2px solid black';\n",
        "      div.style.padding = '3px';\n",
        "      div.style.width = '100%';\n",
        "      div.style.maxWidth = '600px';\n",
        "      document.body.appendChild(div);\n",
        "\n",
        "      const modelOut = document.createElement('div');\n",
        "      modelOut.innerHTML = \"Status:\";\n",
        "      labelElement = document.createElement('span');\n",
        "      labelElement.innerText = 'No data';\n",
        "      labelElement.style.fontWeight = 'bold';\n",
        "      modelOut.appendChild(labelElement);\n",
        "      div.appendChild(modelOut);\n",
        "\n",
        "      video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      video.width = div.clientWidth - 6;\n",
        "      video.setAttribute('playsinline', '');\n",
        "      video.onclick = () => { shutdown = true; };\n",
        "      stream = await navigator.mediaDevices.getUserMedia(\n",
        "          {video: { facingMode: \"environment\"}});\n",
        "      div.appendChild(video);\n",
        "\n",
        "      imgElement = document.createElement('img');\n",
        "      imgElement.style.position = 'absolute';\n",
        "      imgElement.style.zIndex = 1;\n",
        "      imgElement.onclick = () => { shutdown = true; };\n",
        "      div.appendChild(imgElement);\n",
        "\n",
        "      const instruction = document.createElement('div');\n",
        "      instruction.innerHTML =\n",
        "          '' +\n",
        "          'When finished, click here or on the video to stop this demo';\n",
        "      div.appendChild(instruction);\n",
        "      instruction.onclick = () => { shutdown = true; };\n",
        "\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      captureCanvas = document.createElement('canvas');\n",
        "      captureCanvas.width = 640; //video.videoWidth;\n",
        "      captureCanvas.height = 480; //video.videoHeight;\n",
        "      window.requestAnimationFrame(onAnimationFrame);\n",
        "\n",
        "      return stream;\n",
        "    }\n",
        "    async function stream_frame(label, imgData) {\n",
        "      if (shutdown) {\n",
        "        removeDom();\n",
        "        shutdown = false;\n",
        "        return '';\n",
        "      }\n",
        "\n",
        "      var preCreate = Date.now();\n",
        "      stream = await createDom();\n",
        "\n",
        "      var preShow = Date.now();\n",
        "      if (label != \"\") {\n",
        "        labelElement.innerHTML = label;\n",
        "      }\n",
        "\n",
        "      if (imgData != \"\") {\n",
        "        var videoRect = video.getClientRects()[0];\n",
        "        imgElement.style.top = videoRect.top + \"px\";\n",
        "        imgElement.style.left = videoRect.left + \"px\";\n",
        "        imgElement.style.width = videoRect.width + \"px\";\n",
        "        imgElement.style.height = videoRect.height + \"px\";\n",
        "        imgElement.src = imgData;\n",
        "      }\n",
        "\n",
        "      var preCapture = Date.now();\n",
        "      var result = await new Promise(function(resolve, reject) {\n",
        "        pendingResolve = resolve;\n",
        "      });\n",
        "      shutdown = false;\n",
        "\n",
        "      return {'create': preShow - preCreate,\n",
        "              'show': preCapture - preShow,\n",
        "              'capture': Date.now() - preCapture,\n",
        "              'img': result};\n",
        "    }\n",
        "    ''')\n",
        "\n",
        "  display(js)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mELCiQRrKdcY"
      },
      "outputs": [],
      "source": [
        "def video_frame(label, bbox):\n",
        "  data = eval_js('stream_frame(\"{}\", \"{}\")'.format(label, bbox))\n",
        "  return data\n",
        "\n",
        "\n",
        "# start streaming video from webcam\n",
        "video_stream()\n",
        "# label for video\n",
        "label_html = 'Capturing...'\n",
        "# initialze bounding box to empty\n",
        "bbox = ''\n",
        "count = 0\n",
        "i =0\n",
        "reali = 0 ; name = \"\" ; label = \"Proxy\" ; resulted_founded_names = []\n",
        "while True:\n",
        "    js_reply = video_frame(label_html, bbox)\n",
        "    if not js_reply:\n",
        "        i = 0 ; reali = 0\n",
        "        break\n",
        "\n",
        "    # convert JS response to OpenCV Image\n",
        "    img = js_to_image(js_reply[\"img\"])\n",
        "\n",
        "    # create transparent overlay for bounding box\n",
        "    bbox_array = np.zeros([480,640,4], dtype=np.uint8)\n",
        "\n",
        "    #\n",
        "    frame = img\n",
        "    #\n",
        "\n",
        "    # grayscale image for face detection\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
        "\n",
        "    try:\n",
        "      faces = face_cascade.detectMultiScale(gray,1.3,5)\n",
        "      for (x,y,w,h) in faces:\n",
        "        print(\"number\",i); i+=1\n",
        "        face = frame[y-5:y+h+5,x-5:x+w+5]\n",
        "        resized_face = cv2.resize(face,(160,160))\n",
        "        resized_face = resized_face.astype(\"float\") / 255.0\n",
        "        # resized_face = img_to_array(resized_face)\n",
        "        resized_face = np.expand_dims(resized_face, axis=0)\n",
        "        # pass the face ROI through the trained liveness detector\n",
        "        # model to determine if the face is \"real\" or \"Proxy\"\n",
        "        print(\"just came/...\")\n",
        "        preds = model.predict(resized_face)[0]\n",
        "        print(\">>preds>>\",preds)\n",
        "        if preds> 0.5:\n",
        "            label = 'spoof'\n",
        "            cv2.putText(frame, label, (x,y - 10),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,255), 2)\n",
        "            cv2.rectangle(frame, (x, y), (x+w,y+h),\n",
        "                (0, 0, 255), 2)\n",
        "        else:\n",
        "            label = 'real'\n",
        "            reali += 1\n",
        "            cv2.putText(frame, label, (x,y - 10),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,255,0), 2)\n",
        "            cv2.rectangle(frame, (x, y), (x+w,y+h),\n",
        "            (0, 255, 0), 2)\n",
        "        # save image\n",
        "        filename = \"photo.jpg\"\n",
        "        cv2.imwrite(filename, frame)\n",
        "        print('Saved to {}'.format(filename))\n",
        "        display(Image(filename))\n",
        "        print(\"result>>\",label)\n",
        "    except: pass\n",
        "#----------------------------------------------------\n",
        "    if label =='real':\n",
        "      label = \"Proxy\"\n",
        "      # Load test image\n",
        "      test_image_path = \"/content/photo.jpg\"\n",
        "      test_image = face_recognition.load_image_file(test_image_path)\n",
        "\n",
        "      # Define face recognition function\n",
        "      def recognize_face(face_encoding):\n",
        "          matches = face_recognition.compare_faces(known_face_encodings, face_encoding, tolerance=0.4)\n",
        "          if True in matches:\n",
        "              match_index = matches.index(True)\n",
        "              name = known_face_names[match_index]\n",
        "              return name\n",
        "          else:\n",
        "              return None\n",
        "\n",
        "      # Find faces in test image\n",
        "      face_locations = face_recognition.face_locations(test_image, model='cnn')\n",
        "      face_encodings = face_recognition.face_encodings(test_image, face_locations, num_jitters=10, model=\"large\")\n",
        "\n",
        "      # Create or open attendance file in append mode\n",
        "      attendance_file = open(\"/content/drive/MyDrive/Colab Notebooks/Real Time Face Recognition System/Attendance folder/Attendance.txt\", \"a\")\n",
        "\n",
        "\n",
        "      # Check if test image contains at least one face\n",
        "      if not face_encodings:\n",
        "          print(\"No faces found in test image.\")\n",
        "      else:\n",
        "          # Parallelize face recognition process\n",
        "          with concurrent.futures.ProcessPoolExecutor() as executor:\n",
        "              results = executor.map(recognize_face, face_encodings)\n",
        "          resulted_founded_names = list(results)\n",
        "          # Write attendance to file\n",
        "          for i, result in enumerate(results):\n",
        "              if result:\n",
        "                  name = result\n",
        "                  resulted_founded_names.append(name)\n",
        "                  print(f\"Match found: {name}\")\n",
        "\n",
        "              else:\n",
        "                  print(\"No match found.\")\n",
        "      #-----------------------------------------------------\n",
        "\n",
        "    #--------CODE FOR EMAIL SENDING ----------------------\n",
        "import smtplib\n",
        "import ssl\n",
        "from email.message import EmailMessage\n",
        "from datetime import datetime\n",
        "import collections\n",
        "from pytz import timezone\n",
        "resulted_founded_names = ['RohiTh']\n",
        "d = collections.defaultdict(lambda : 'Not found')\n",
        "d ['RohiTh'] = ['2022it0093@svce.ac.in','2127220801072'] ;       d['Praveen'] = ['2022it0109@svce.ac.in' ,'Number__solra']\n",
        "d ['Thiwahar']  = ['2022it0535@svce.ac.in','2127220801101'] ;  d['Sanjay Ram']  = ['2022it0899@svce.ac.in', '2127220801076']\n",
        "for name in resulted_founded_names:\n",
        "  try:\n",
        "    if d[name] == 'Not found': pass\n",
        "\n",
        "  ##################################\n",
        "    def update_login(student_name):\n",
        "      file_path = '/content/drive/MyDrive/AutoMailingFeatureForAttendanceSystem/login.txt'\n",
        "      # student_name = input(\"Enter student name: \")\n",
        "\n",
        "      with open(file_path, 'r') as file:\n",
        "          lines = file.readlines()\n",
        "      # print(\"initial>\",lines)\n",
        "\n",
        "      found = 0\n",
        "      new_lines = []\n",
        "\n",
        "      for line in lines:\n",
        "          if line.strip() == student_name:\n",
        "              found = 1\n",
        "              print(found,\"<<\")\n",
        "              continue\n",
        "          else:\n",
        "              new_lines.append(line)\n",
        "\n",
        "      if not found:\n",
        "          new_lines.append(student_name + '\\n')\n",
        "\n",
        "      with open(file_path, 'w') as file:\n",
        "          file.writelines(new_lines)\n",
        "\n",
        "      with open(file_path, 'r') as file:\n",
        "          lines = file.readlines()\n",
        "      return found\n",
        "      # print(\"final>\",lines)\n",
        "    ##################################\n",
        "    founded = update_login(name)\n",
        "    res_loginRout = \"Login time\"\n",
        "    if founded: res_loginRout = \"Logout time\"\n",
        "    print(founded,res_loginRout)\n",
        "    for i in range(1):\n",
        "      # Get the current date and time\n",
        "      now = datetime.now(timezone(\"Asia/Kolkata\"))\n",
        "      current_time = now.strftime(\"%H:%M:%S\")\n",
        "      current_date = now.strftime(\"%d/%m/%Y\")\n",
        "\n",
        "      # for i in range(10):\n",
        "      # Define email sender and receiver\n",
        "      email_sender = 'rohith777here@gmail.com'\n",
        "      email_password = 'ckek bcij lhkh fqmi'\n",
        "      email_receiver = d[name][0]#'skgouse131@gmail'#'bnagaseshu2001@gmail.com'#'vilasagaram.vikas@gmail.com'#'skgouse131@gmail.com'\n",
        "\n",
        "      # Set the subject and body of the email\n",
        "      subject = 'SVCE REAL-TIME FACE RECOGNITION BASED ATTENDANCE MONITORING SYSTEM.'#'Check out Your ward attendance!'\n",
        "      body = f\"\"\"\n",
        "      <<<<<<<<<<<<<   YOUR ATTENDANCE   >>>>>>>>>>>>>>>\n",
        "      -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "      RollNo : {d[name][1]}\n",
        "      NAME : {name}\n",
        "      DATE : {current_date}\n",
        "      TIME : {current_time}\n",
        "      {name} {res_loginRout} attended on {current_date} at {current_time} has successfully marked the attendance.\n",
        "      ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "      Dear {d[name][0]}, \\n\n",
        "      This message is from Organisation/college automatic attendance system. \\n\n",
        "      Your attendance has been successfully marked using the face recognition system. This means that you have been present and accounted for during work hours. I would like to take this opportunity to congratulate you on your successful use of the system.\n",
        "      \\n\n",
        "      The face recognition system has also enhanced our security measures, as it only allows authorized personnel with registered faces to enter the premises. This ensures that our workplace remains safe and secure at all times.\n",
        "      \\n\n",
        "      As a Organisation/college attendance system would like to remind you to continue using the face recognition system for attendance marking. It is important that we maintain accurate attendance records to ensure that everyone is accounted for during work hours..\n",
        "      \\n\n",
        "      Thank you for your attention to this matter.\n",
        "      \\n\n",
        "      Best regards,\n",
        "      \\n\n",
        "      {name}\"\"\"\n",
        "\n",
        "      em = EmailMessage()\n",
        "      em['From'] = 'XYZ'#email_sender\n",
        "      em['To'] = email_receiver\n",
        "      em['Subject'] = subject\n",
        "      em.set_content(body)\n",
        "\n",
        "      # Add SSL (layer of security)\n",
        "      context = ssl.create_default_context()\n",
        "\n",
        "      # Log in and send the email\n",
        "      with smtplib.SMTP_SSL('smtp.gmail.com', 465, context=context) as smtp:\n",
        "          smtp.login(email_sender, email_password)\n",
        "          smtp.sendmail(email_sender, email_receiver, em.as_string())\n",
        "      print(f\"emailsent to {name}\")\n",
        "    resulted_founded_names = []\n",
        "  except:\n",
        "    print(\"NO match found\")\n",
        "#------------------------------------------------------------------------\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1ge2b4SsE-ebY0eOWEZUs9UHCm8vexAym",
      "authorship_tag": "ABX9TyNUOSiVXkXYGSMYb41ePZ4Q",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}